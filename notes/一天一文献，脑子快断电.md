## 1.01基于度量学习的少样本图像分类方法研究_贾冰

这篇论文提了两个并行的算法，SSOFR 关注的是如何通过更好的**训练范式**（自监督）来获得一个更强大的通用特征提取器。而 PVInet 关注的是如何通过更复杂的**概率建模**来处理不确定性和困难的数据分布。

### 1.关键词：

少样本学习、自监督学习，变分推理

### 2.数据集：

Mini-ImageNet[56]：ImageNet 中随机抽取的一个子集，该数据集包含 100 个类别，每个类别拥有 600 幅图像，整个数据集拥有 60000 幅图像

Tiered-ImageNet[57]：同样取于 ImageNet 数据集，其中大类别有 34 个，小类别有 608 个，每个类别大概有 1300 张样本图像

CUB-200-2011：是用于细粒度图像分类的鸟类数据集，该数据集一共 11788 张图像，包含 200 种不同的鸟类

CIFAR-FS[67]和 FC100[68]

### 3.陌生词汇：

#### 1.度量学习：

​	度量学习（Metric Learning），又称距离度量学习或相似度学习，是一种旨在让机器学习模型学会如何衡量数据之间相似性的重要方法。其核心思想是，根据特定任务的需求，自动学习出一个距离函数，使得在由该函数定义的特征空间中，相似的样本能够相互靠近，而不相似的样本则相互远离。

​	想象一下，我们希望计算机能够识别人脸。传统的分类方法可能会为每个已知的人训练一个分类器。但如果出现一个新的人，就需要重新训练模型。度量学习则另辟蹊径，它不直接学习识别人脸的类别，而是学习一个“度量标准”，能够计算出两张人脸照片的“相似度得分”。如果得分高于某个阈值，就判断为同一个人，反之则不是。这样，即使遇到从未见过的人脸，模型也能够通过比较其与已知人脸的相似度来进行识别，这便是度量学习的精妙之处。

#### 2.类间差异小，类内差异大

当“类内差异大”和“类间差异小”同时发生时，分类任务变得异常困难。

- 一张你**大笑的侧脸照片**，可能跟你**严肃的正脸照片**看起来差别很大（类内差异大）。
- 同时，这张你**严肃的正脸照片**，可能跟另一个**长得像你的人的照片**看起来非常相似（类间差异小）。

这就导致了一个严重的问题：**一张你自己的照片（同类）和你“撞脸”的人的照片（异类），哪一个更像你的标准照？答案很可能是不确定的。**

对于分类模型来说，它学习到的特征空间会变得非常混乱，不同类别的特征分布会大量重叠在一起，很难画出一条清晰的界线来区分它们。

#### 3.支持集和查询集

==支持集 (Support Set)==

- **角色：** 模型的“**临时学习样本**”或“**上下文信息**”。
- **构成：** 包含 `N` 个类别，每个类别有 `K` 个带标签的样本。这就是我们常说的 `N-way K-shot` 任务。例如，一个 `5-way 1-shot` 的支持集就包含5个类别，每个类别仅有1张照片。
- **目的：** 模型需要观察支持集，快速**学习并理解**这 `N` 个在之前（大规模训练阶段）可能从未见过的新类别的特征是什么。例如，模型通过支持集学习到“长着巨大彩色嘴巴的鸟是巨嘴鸟”。

==查询集 (Query Set)==

- **角色：** 模型的“**临时测试样本**”。
- **构成：** 包含若干个**不带标签**（对模型而言）的样本，这些样本的真实类别也属于支持集中的那 `N` 个类别之一。**重要的是，查询集中的图片与支持集中的图片不能重复。**
- **目的：** 用来**评估**模型刚刚从支持集中学到的“举一反三”的能力。模型的任务是为查询集中的每一个样本，正确地分配一个来自支持集 `N` 个类别中的标签。模型的预测准确率，就是它在这次“随堂考”中的分数。

和普通训练集验证集的区别是，支持集和查询集提供的类别是之前从未见过的类别，模型必须动用它学到的“快速学习”能力，现场分析支持集，然后对查询集进行分类。

### 4.Gemeni给出的原型网络训练思路

使用 Mini-ImageNet 数据集，按照训练集、验证集、测试集 64/16/20 类别划分，训练一个标准的少样本（FSL）模型的正确、完整步骤。

我们将以经典的**原型网络（Prototypical Networks）**作为示例模型，因为它的流程非常清晰，能够很好地体现 FSL 的核心思想。

#### **准备阶段：理解数据划分**

首先，您给出的数据划分是 FSL 的标准做法，这一步非常关键：

- **元训练集 (Meta-training Set):** 64 个基类（Base Classes）。模型将在这个集合上学习“如何学习”。
- **元验证集 (Meta-validation Set):** 16 个验证类（Validation Classes）。这些类别在训练中**不可见**。用来调整超参数和选择最佳模型。
- **元测试集 (Meta-testing Set):** 20 个新类（Novel Classes）。这些类别在训练和验证中都**不可见**。用来最终报告模型的性能。

**核心原则：** 这三个类别集合之间**绝不能有任何交集**。模型的能力是通过在全新类别上的表现来衡量的。

#### **正确的训练步骤**

整个流程分为三个主要阶段：

#### **阶段一：元训练 (Meta-training) - 在 64 个基类上学习**

这是模型的核心训练阶段。其目标不是学会识别这64个类，而是学会一个**通用的特征嵌入空间（Embedding Space）**，使得任何新类别只要有少数样本，就能在这个空间里很好地被区分开。

这个阶段通过**“任务式训练”（Episodic Training）**来完成。

**模型组件：**

- 一个特征提取器 fθ (通常是卷积神经网络, 如 ResNet)，θ 是其需要学习的参数。
- 一个优化器（如 Adam）。

**训练循环（会重复成千上万次）：**

第 1 步：构造一个“任务（Episode）”

在每一次迭代中，我们都模拟一次 N-way K-shot 的“小考试”。假设我们进行 5-way 5-shot 的训练：

- **(a)** 从 64 个训练类中，**随机**挑选 N=5 个类别。
- **(b)** 对于这 5 个类中的每一个，**随机**从其 600 张图片中挑选 K+Q 张图片。例如，K=5（支持样本），Q=15（查询样本）。
- **(c) 构建支持集 (Support Set)：** 包含 N×K = 5×5 = 25 张图片，并附带它们的标签。
- **(d) 构建查询集 (Query Set)：** 包含 N×Q = 5×15 = 75 张图片，也附带它们的标签（标签在计算损失时使用）。

**第 2 步：计算类别的“原型（Prototypes）”**

- **(a)** 将**支持集**中的全部 25 张图片，逐一通过特征提取器 fθ，得到 25 个嵌入向量（embedding）。
- **(b)** 对属于同一类别的 K 个嵌入向量进行**平均**，得到该类的**原型向量**。
- **(c)** 最终，我们会得到 N=5 个原型向量 {c₁, c₂, c₃, c₄, c₅}，分别代表这 5 个临时类别的中心。

**第 3 步：在查询集上进行预测**

- **(a)** 将**查询集**中的全部 75 张图片，逐一通过同一个特征提取器 fθ，得到 75 个嵌入向量 {xq}。
- **(b)** 对于每一个查询向量 xq，计算它与 5 个原型向量 {c₁...c₅} 之间的**距离**（通常使用欧氏距离的平方）。这样，每个查询样本都会得到 5 个距离值。

**第 4 步：计算损失 (Loss)**

- **(a)** 将上一步得到的距离值转化为概率分布。通常的做法是取负距离，然后应用 Softmax 函数。一个查询样本离哪个原型近，其对应的概率就高。
- **(b)** 使用标准的**交叉熵损失函数**，比较模型为查询集计算出的概率分布和查询集的**真实标签**。
- **(c)** 得到这个“任务（Episode）”的最终损失值。

**第 5 步：更新模型参数**

- 基于计算出的损失，进行反向传播，**更新特征提取器 fθ 的参数 θ**。

这个从第 1 步到第 5 步的完整循环会重复进行，直到模型的性能在验证集上饱和。

#### **阶段二：元验证 (Meta-validation) - 在 16 个验证类上选择最佳模型**

这个阶段的目的是**监控训练过程**并**保存最好的模型**，而不是继续训练模型。

**流程：**

1. 在元训练进行了一定次数的迭代后（比如每 500 个 episodes），**暂停训练**。
2. 切换到**元验证集**（16 个从未见过的类别）。
3. **不进行梯度更新**，纯粹进行评估。构造大量的验证“任务”（比如 600 个 episodes），每个任务都从 16 个验证类中采样构成。
4. 对于每个任务，按照**元训练的第 2、3 步**进行预测，并计算其在查询集上的**准确率**。
5. 计算这 600 个任务的**平均准确率**。
6. 如果当前的平均准确率是历史最高的，则**保存当前的模型参数 θ**。
7. **恢复元训练**。

这个过程就像学生在复习（元训练）一段时间后，做一套模拟题（元验证）看看自己进步了多少。

#### **阶段三：元测试 (Meta-testing) - 在 20 个测试类上报告最终性能**

当整个元训练过程结束后，我们从元验证阶段挑选出了一个“最佳模型”。现在，我们要在最终的考场上检验它的真实水平。

**流程：**

1. 加载在元验证阶段保存的**最佳模型**。
2. 切换到**元测试集**（20 个完全陌生的类别）。
3. 像元验证一样，构造大量的测试“任务”（通常是 1000 到 2000 个，以获得稳定的结果）。
4. **不进行任何参数更新**，让模型完成这些任务，并记录每个任务的准确率。
5. 计算所有测试任务的**平均准确率**和**95%置信区间**。

这个最终的平均准确率，就是衡量你的少样本模型性能的最终指标。

## 2.02基于对比学习的水下鱼类图像分类研究_颜乾坤

这篇也是提出两种算法，第一个算法用Resnet50作为基线模型，提出基于监督对比学习的水下鱼类图像分类方法，通过修改残差网络、引入注意力机制ECA、调整损失函数（监督对比损失）实现，第二个算法基于SimCLR，提出基于忽视背景对比学习的水下鱼类图像分类方法CLIB，具体怎么改的，懒得看了。

### SE注意力机制：

论文地址：https://arxiv.org/abs/1709.01507

论文源代码：[hujie-frank/SENet: Squeeze-and-Excitation Networks](https://github.com/hujie-frank/SENet)



### CBAM注意力机制：



### 对比学习：
